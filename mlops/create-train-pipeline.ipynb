{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create & Run AML Train Pieline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, dsl, Input, Output, MLClient\n",
        "from azure.identity import DefaultAzureCredential"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_compute_target = \"paolt-run-cpu-vm\"\n",
        "environment_name = \"DataBook-Env\"\n",
        "environment_ver = \"3\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data_prep_component = command(\n",
        "    name=\"data_prep_dbcc\",\n",
        "    display_name=\"Data preparation for training\",\n",
        "    inputs={\"data\": Input(type=\"uri_file\", mode=\"ro_mount\"),\n",
        "        \"ranges\": Input(type=\"uri_file\", mode=\"ro_mount\"),\n",
        "        \"test_train_ratio\": Input(type=\"number\")},\n",
        "    outputs={\"train_data\" : Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        \"test_data\" : Output(type=\"uri_folder\", mode=\"rw_mount\")},\n",
        "    code=\"./scripts\",\n",
        "    command=\"\"\"python data-prep-stage-script.py \\\n",
        "            --data ${{inputs.data}} --ranges ${{inputs.ranges}} --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
        "            --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"{environment_name}:{environment_ver}\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_component = command(\n",
        "    name=\"train_dbcc\",\n",
        "    display_name=\"Train classifier\",\n",
        "    inputs={\"train_data\" : Input(type=\"uri_folder\", mode=\"ro_mount\"),\n",
        "        \"test_data\" : Input(type=\"uri_folder\", mode=\"ro_mount\")},\n",
        "    outputs={\"model_path\": Output(type=\"uri_folder\", mode=\"rw_mount\")},\n",
        "    code=\"./scripts\",\n",
        "    command=\"\"\"python train-stage-script.py \\\n",
        "            --train_data ${{inputs.train_data}} \\\n",
        "            --test_data ${{inputs.test_data}} \\\n",
        "            --model_path ${{outputs.model_path}}\n",
        "            \"\"\",\n",
        "    environment=f\"{environment_name}:{environment_ver}\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    compute=cpu_compute_target,\n",
        "    description=\"DBCC data_perp-train pipeline\",\n",
        ")\n",
        "def dbcc_pipeline(\n",
        "    pipeline_job_data_input,\n",
        "    pipeline_job_ranges_input,\n",
        "    pipeline_job_test_train_ratio=0.25,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    data_prep_job = data_prep_component(\n",
        "        data=pipeline_job_data_input,\n",
        "        ranges=pipeline_job_ranges_input,\n",
        "        test_train_ratio=pipeline_job_test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # using train_func like a python call with its own inputs\n",
        "    train_job = train_component(\n",
        "        train_data=data_prep_job.outputs.train_data,\n",
        "        test_data=data_prep_job.outputs.test_data,\n",
        "    )\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"pipeline_job_train_data\": data_prep_job.outputs.train_data,\n",
        "        \"pipeline_job_test_data\": data_prep_job.outputs.test_data,\n",
        "        \"pipeline_job_model\": train_job.outputs.model_path,\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = dbcc_pipeline(\n",
        "    pipeline_job_data_input=Input(type=\"uri_file\", path=\"azureml://datastores/workspaceblobstore/paths/dbcc_data/Standard_Databook_06_07_2022.csv.json\", mode=\"ro_mount\"),\n",
        "    pipeline_job_ranges_input=Input(type=\"uri_file\", path=\"azureml://datastores/workspaceblobstore/paths/dbcc_data/areas.txt\", mode=\"ro_mount\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client = MLClient.from_config(\n",
        "    credential=DefaultAzureCredential())\n",
        "ml_client"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/paolt-dev-cpu-vm/code/Users/paolt/databook_v1/.azureml/config.json\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f999fd1f910>,\n         subscription_id=fadb1e32-9c96-4180-be9d-1811f4687cca,\n         resource_group_name=paolt-ml-v2,\n         workspace_name=paolt-ml-v2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    experiment_name=\"dbcc-test\",\n",
        ")\n",
        "pipeline_job"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading scripts (0.01 MBs): 100%|██████████| 7123/7123 [00:00<00:00, 146084.47it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "PipelineJob({'inputs': {'pipeline_job_data_input': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7f999c896910>, 'pipeline_job_ranges_input': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7f999c8967f0>, 'pipeline_job_test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7f999c896220>}, 'outputs': {'pipeline_job_train_data': <azure.ai.ml.entities._job.pipeline._io.PipelineOutput object at 0x7f999c896b20>, 'pipeline_job_test_data': <azure.ai.ml.entities._job.pipeline._io.PipelineOutput object at 0x7f999c896b50>, 'pipeline_job_model': <azure.ai.ml.entities._job.pipeline._io.PipelineOutput object at 0x7f999c896af0>}, 'component': PipelineComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'name': 'azureml_anonymous', 'description': 'DBCC data_perp-train pipeline', 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f999c8d9490>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'dbcc_pipeline', 'is_deterministic': True, 'inputs': {'pipeline_job_data_input': {'type': 'unknown'}, 'pipeline_job_ranges_input': {'type': 'unknown'}, 'pipeline_job_test_train_ratio': {'type': 'unknown'}}, 'outputs': {'pipeline_job_train_data': {'type': 'unknown'}, 'pipeline_job_test_data': {'type': 'unknown'}, 'pipeline_job_model': {'type': 'unknown'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] dbcc_pipeline at 0x7f999fd3daf0>, 'jobs': {'data_prep_job': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'data_prep_job', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f999c8969d0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Data preparation for training', 'experiment_name': None, 'compute': None, 'services': None, 'job_inputs': {'data': '${{parent.inputs.pipeline_job_data_input}}', 'ranges': '${{parent.inputs.pipeline_job_ranges_input}}', 'test_train_ratio': '${{parent.inputs.pipeline_job_test_train_ratio}}'}, 'job_outputs': {'train_data': '${{parent.outputs.pipeline_job_train_data}}', 'test_data': '${{parent.outputs.pipeline_job_test_data}}'}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7f999c896880>, 'ranges': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7f999c896a90>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7f999c896a60>}, 'outputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.PipelineOutputBase object at 0x7f999fcd7130>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.PipelineOutputBase object at 0x7f999fcd72b0>}, 'component': 'azureml_anonymous:c81d83c9-b1d3-44c4-8742-40af40f5023e', 'kwargs': {}, 'instance_id': 'e2099228-6d9b-440d-baf9-2ee35696cd4e', 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'swept': False}), 'train_job': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'train_job', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f999c896e80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Train classifier', 'experiment_name': None, 'compute': None, 'services': None, 'job_inputs': {'train_data': '${{parent.jobs.data_prep_job.outputs.train_data}}', 'test_data': '${{parent.jobs.data_prep_job.outputs.test_data}}'}, 'job_outputs': {'model_path': '${{parent.outputs.pipeline_job_model}}'}, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7f999fcd7220>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7f999fcd70d0>}, 'outputs': {'model_path': <azure.ai.ml.entities._job.pipeline._io.PipelineOutputBase object at 0x7f999fcd70a0>}, 'component': 'azureml_anonymous:a010d79b-eb89-49f1-b77c-a9cd71b65eda', 'kwargs': {}, 'instance_id': '642df108-4dff-4d48-b674-7bb10cec1b07', 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'swept': False})}, 'job_types': {'command': 2}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'elated_library_srll63wvh7', 'description': 'DBCC data_perp-train pipeline', 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/PAOLT/databook_v1.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'a57f5214469bd6f05fd7fa33856a178ab2697c95', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"pipeline_job_test_train_ratio\":\"0.25\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.defaultComputeName': 'paolt-run-cpu-vm', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/fadb1e32-9c96-4180-be9d-1811f4687cca/resourceGroups/paolt-ml-v2/providers/Microsoft.MachineLearningServices/workspaces/paolt-ml-v2/jobs/elated_library_srll63wvh7', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/paolt-dev-cpu-vm/code/Users/paolt/databook_v1/mlops', 'creation_context': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x7f999c84d130>, 'serialize': <msrest.serialization.Serializer object at 0x7f999c896c40>, 'display_name': 'dbcc_pipeline', 'experiment_name': 'dbcc-test', 'compute': 'paolt-run-cpu-vm', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f999c84d280>, 'Studio': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f999c84d2b0>}, 'settings': <azure.ai.ml.entities._job.pipeline.pipeline_job_settings.PipelineJobSettings object at 0x7f999fcd7250>, 'identity': None, 'default_code': None, 'default_environment': None})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>dbcc-test</td><td>elated_library_srll63wvh7</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/elated_library_srll63wvh7?wsid=/subscriptions/fadb1e32-9c96-4180-be9d-1811f4687cca/resourcegroups/paolt-ml-v2/workspaces/paolt-ml-v2&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}